{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a17e8e1-5dd1-4e4e-a4cb-c79d7a192ca5",
   "metadata": {},
   "source": [
    "#### 1. Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59173387-2f20-4620-aaf4-db53eb1ff6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle, random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Dense, Dropout, LeakyReLU, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49c8517-be8c-4386-ac10-3e8d9e7de1c1",
   "metadata": {},
   "source": [
    "#### 2. Load data, transfer to pands dataframes, and review the first 3 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8aa3d78-f76d-427a-9521-1bedfe4cb7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_emb_file = '/home/drorco/DC_corsound_submission/audio_embeddings.pickle'\n",
    "face_emb_file = '/home/drorco/DC_corsound_submission/image_embeddings.pickle'\n",
    "\n",
    "audio_emb = pickle.load(open(audio_emb_file, \"rb\"))\n",
    "face_emb = pickle.load(open(face_emb_file, \"rb\"))\n",
    "\n",
    "audio_df =  pd.DataFrame.from_dict(audio_emb).T.reset_index()\n",
    "face_df =  pd.DataFrame.from_dict(face_emb).T.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39b2efbc-fbd0-408f-bcdb-44265708f5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ronan_Farrow/aaSZM4e7AU8/00102.wav</td>\n",
       "      <td>33.898537</td>\n",
       "      <td>3.921535</td>\n",
       "      <td>-20.368700</td>\n",
       "      <td>-47.556862</td>\n",
       "      <td>-4.989654</td>\n",
       "      <td>-18.455454</td>\n",
       "      <td>12.782804</td>\n",
       "      <td>19.325085</td>\n",
       "      <td>6.648265</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.505846</td>\n",
       "      <td>13.317440</td>\n",
       "      <td>16.088955</td>\n",
       "      <td>10.481414</td>\n",
       "      <td>-1.055707</td>\n",
       "      <td>3.693741</td>\n",
       "      <td>32.395004</td>\n",
       "      <td>3.947245</td>\n",
       "      <td>-0.548808</td>\n",
       "      <td>-32.880100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ronan_Farrow/iHoOkskbwz8/00141.wav</td>\n",
       "      <td>2.208049</td>\n",
       "      <td>-27.211391</td>\n",
       "      <td>12.965365</td>\n",
       "      <td>21.879303</td>\n",
       "      <td>10.028281</td>\n",
       "      <td>14.146223</td>\n",
       "      <td>-32.257832</td>\n",
       "      <td>-4.648191</td>\n",
       "      <td>16.460787</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.311125</td>\n",
       "      <td>-8.107459</td>\n",
       "      <td>2.558080</td>\n",
       "      <td>-32.009212</td>\n",
       "      <td>-29.041698</td>\n",
       "      <td>20.518143</td>\n",
       "      <td>-1.100664</td>\n",
       "      <td>1.003822</td>\n",
       "      <td>31.168587</td>\n",
       "      <td>13.086949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ronan_Farrow/DTLV2-9nMNI/00034.wav</td>\n",
       "      <td>9.009793</td>\n",
       "      <td>41.082924</td>\n",
       "      <td>-10.212173</td>\n",
       "      <td>-25.880884</td>\n",
       "      <td>15.122940</td>\n",
       "      <td>-4.969586</td>\n",
       "      <td>1.046486</td>\n",
       "      <td>13.861155</td>\n",
       "      <td>9.851394</td>\n",
       "      <td>...</td>\n",
       "      <td>2.750567</td>\n",
       "      <td>10.616673</td>\n",
       "      <td>7.339180</td>\n",
       "      <td>-5.395815</td>\n",
       "      <td>11.826921</td>\n",
       "      <td>-13.325937</td>\n",
       "      <td>23.457645</td>\n",
       "      <td>-6.737992</td>\n",
       "      <td>9.119067</td>\n",
       "      <td>-15.492328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                index          0          1          2  \\\n",
       "0  Ronan_Farrow/aaSZM4e7AU8/00102.wav  33.898537   3.921535 -20.368700   \n",
       "1  Ronan_Farrow/iHoOkskbwz8/00141.wav   2.208049 -27.211391  12.965365   \n",
       "2  Ronan_Farrow/DTLV2-9nMNI/00034.wav   9.009793  41.082924 -10.212173   \n",
       "\n",
       "           3          4          5          6          7          8  ...  \\\n",
       "0 -47.556862  -4.989654 -18.455454  12.782804  19.325085   6.648265  ...   \n",
       "1  21.879303  10.028281  14.146223 -32.257832  -4.648191  16.460787  ...   \n",
       "2 -25.880884  15.122940  -4.969586   1.046486  13.861155   9.851394  ...   \n",
       "\n",
       "         182        183        184        185        186        187  \\\n",
       "0  -6.505846  13.317440  16.088955  10.481414  -1.055707   3.693741   \n",
       "1 -16.311125  -8.107459   2.558080 -32.009212 -29.041698  20.518143   \n",
       "2   2.750567  10.616673   7.339180  -5.395815  11.826921 -13.325937   \n",
       "\n",
       "         188       189        190        191  \n",
       "0  32.395004  3.947245  -0.548808 -32.880100  \n",
       "1  -1.100664  1.003822  31.168587  13.086949  \n",
       "2  23.457645 -6.737992   9.119067 -15.492328  \n",
       "\n",
       "[3 rows x 193 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56de7015-0bc1-431f-9a3e-d49af1794754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ronan_Farrow/1.jpg</td>\n",
       "      <td>-0.059632</td>\n",
       "      <td>0.064536</td>\n",
       "      <td>-0.008410</td>\n",
       "      <td>-0.055838</td>\n",
       "      <td>0.028547</td>\n",
       "      <td>-0.109469</td>\n",
       "      <td>-0.018306</td>\n",
       "      <td>0.055878</td>\n",
       "      <td>0.032933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069911</td>\n",
       "      <td>-0.037521</td>\n",
       "      <td>0.045062</td>\n",
       "      <td>0.059087</td>\n",
       "      <td>0.006203</td>\n",
       "      <td>0.057657</td>\n",
       "      <td>-0.045365</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>-0.009480</td>\n",
       "      <td>-0.031032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ronan_Farrow/3.jpg</td>\n",
       "      <td>-0.071796</td>\n",
       "      <td>0.073578</td>\n",
       "      <td>-0.004804</td>\n",
       "      <td>-0.075755</td>\n",
       "      <td>0.030988</td>\n",
       "      <td>-0.097710</td>\n",
       "      <td>-0.006907</td>\n",
       "      <td>0.061086</td>\n",
       "      <td>0.034162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054289</td>\n",
       "      <td>-0.036864</td>\n",
       "      <td>0.030649</td>\n",
       "      <td>0.051350</td>\n",
       "      <td>0.012039</td>\n",
       "      <td>0.069078</td>\n",
       "      <td>-0.028601</td>\n",
       "      <td>0.009141</td>\n",
       "      <td>-0.008253</td>\n",
       "      <td>-0.027167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ronan_Farrow/6.jpg</td>\n",
       "      <td>-0.058867</td>\n",
       "      <td>0.064723</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>-0.053614</td>\n",
       "      <td>0.030354</td>\n",
       "      <td>-0.132318</td>\n",
       "      <td>-0.013864</td>\n",
       "      <td>0.022884</td>\n",
       "      <td>0.045510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095136</td>\n",
       "      <td>-0.036495</td>\n",
       "      <td>0.043408</td>\n",
       "      <td>0.076348</td>\n",
       "      <td>0.015769</td>\n",
       "      <td>0.033067</td>\n",
       "      <td>-0.037924</td>\n",
       "      <td>0.010873</td>\n",
       "      <td>0.012708</td>\n",
       "      <td>-0.031592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                index         0         1         2         3         4  \\\n",
       "0  Ronan_Farrow/1.jpg -0.059632  0.064536 -0.008410 -0.055838  0.028547   \n",
       "1  Ronan_Farrow/3.jpg -0.071796  0.073578 -0.004804 -0.075755  0.030988   \n",
       "2  Ronan_Farrow/6.jpg -0.058867  0.064723  0.004169 -0.053614  0.030354   \n",
       "\n",
       "          5         6         7         8  ...       502       503       504  \\\n",
       "0 -0.109469 -0.018306  0.055878  0.032933  ...  0.069911 -0.037521  0.045062   \n",
       "1 -0.097710 -0.006907  0.061086  0.034162  ...  0.054289 -0.036864  0.030649   \n",
       "2 -0.132318 -0.013864  0.022884  0.045510  ...  0.095136 -0.036495  0.043408   \n",
       "\n",
       "        505       506       507       508       509       510       511  \n",
       "0  0.059087  0.006203  0.057657 -0.045365  0.002749 -0.009480 -0.031032  \n",
       "1  0.051350  0.012039  0.069078 -0.028601  0.009141 -0.008253 -0.027167  \n",
       "2  0.076348  0.015769  0.033067 -0.037924  0.010873  0.012708 -0.031592  \n",
       "\n",
       "[3 rows x 513 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f2ad2e-f276-4340-867a-4df3befcdd84",
   "metadata": {},
   "source": [
    "#### 3. Get the identity (Name) in each modality and generate the mean face embedding for each name\n",
    "It appears that the Name (ID) appears in the string inside the 'index', just before the first slash. <br> After the slash comes the identifier of the file. <br> Hence I split the index in both modalities before the first slash, and give a regular numbering for the files of each ID.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4cc7636-e522-4ead-aad8-7a48977ab62f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "audio_df[['s_Name','s_file']] = audio_df['index'].str.split('/', n=1, expand=True)\n",
    "audio_df = audio_df.sort_values(by=['s_Name','index'])\n",
    "audio_df['s_audio_fNum'] = audio_df.groupby('s_Name')['index'].rank(method='first').astype('int')\n",
    "audio_df = audio_df.drop(columns=['index','s_file'])\n",
    "audio_df= audio_df.set_index(['s_Name','s_audio_fNum']).add_prefix('audio_col_').reset_index()\n",
    "\n",
    "audio_cols = [col for col in audio_df.columns if 'col_' in col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5fe5c25-e35c-4102-a0b9-2a2c1a55b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_df[['s_Name','s_file']] = face_df['index'].str.split('/', n=1, expand=True)\n",
    "face_df = face_df.sort_values(by=['s_Name','index'])\n",
    "face_df['s_face_fNum'] = face_df.groupby('s_Name')['index'].rank(method='first').astype('int')\n",
    "face_df = face_df.drop(columns=['index','s_file'])\n",
    "face_df= face_df.set_index(['s_Name','s_face_fNum']).add_prefix('face_col_').reset_index()\n",
    "\n",
    "face_cols = [col for col in face_df.columns if 'col_' in col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72312e3-7b4f-4840-bd81-9b185f8928d6",
   "metadata": {},
   "source": [
    "#### 4. Create an averaged face embedding for each ID\n",
    "The model that I will train is about to transform each of the audio embeddings into a face ambeddings.<br>\n",
    "Since for some of the IDs in the dataset there are more then 1 face embeddings, my goal is to train the model to transform each of the sound embeddings to the average face embedding of the same ID. <br>\n",
    "For this I need to average the face embedding of each ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6255b58b-55d1-42ae-806a-2b16832b24bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_df_grouped = face_df.drop(columns=['s_face_fNum']).groupby(['s_Name']).agg('mean').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290136fc-5e72-491a-bf50-f6c159dc8c49",
   "metadata": {},
   "source": [
    "#### 5. Combine data modalities - all examples of sound with the average face embedding of the same identity.\n",
    "This creates a unified dataset of both modalities that I will next split to train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a6977c3-f9de-4619-87ca-8144d12223f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df  = audio_df.merge(face_df_grouped,on='s_Name',how='inner').dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7237c1-7d3f-49de-853c-3846af6ee5e5",
   "metadata": {},
   "source": [
    "#### 6. Split the data to train, validation, and test, and shuffle the training dataset\n",
    "The testset will contain all family names starting with ['C' , 'D', 'E'] <br>\n",
    "The valset will contain all family names starting with ['A' , 'B']  <br>\n",
    "The trainset will contain all remaining IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "246d438f-4e48-4312-bfe0-e525e6cda505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique IDs in the entire data:  2979\n",
      "The number of unique IDs in the test dataset:  424\n",
      "The number of unique IDs in the validation dataset:  390\n",
      "The number of unique IDs in the training dataset:  2176\n"
     ]
    }
   ],
   "source": [
    "print('The number of unique IDs in the entire data: ', combined_df['s_Name'].nunique())\n",
    "\n",
    "test_grouped_df = combined_df[(combined_df['s_Name'].str.contains('_C'))|(combined_df['s_Name'].str.contains('_D'))|(combined_df['s_Name'].str.contains('_E'))]\n",
    "print('The number of unique IDs in the test dataset: ', test_grouped_df['s_Name'].nunique())\n",
    "\n",
    "val_df =combined_df[(combined_df['s_Name'].str.contains('_A'))|(combined_df['s_Name'].str.contains('_B'))]\n",
    "print('The number of unique IDs in the validation dataset: ', val_df['s_Name'].nunique())\n",
    "\n",
    "reserved_names_list = test_grouped_df['s_Name'].unique().tolist()+val_df['s_Name'].unique().tolist()\n",
    "train_df = combined_df[~combined_df['s_Name'].isin(reserved_names_list)]\n",
    "print('The number of unique IDs in the training dataset: ',train_df['s_Name'].nunique())\n",
    "\n",
    "train_df = train_df.sample(frac = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe1683c-fd83-486e-93d6-d9830d0e95d1",
   "metadata": {},
   "source": [
    "#### 7. Reserve a similar testset, with the same IDS, only with the original face embeddings (not-averaged) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68c51826-0672-4366-995f-ecd1e1abc7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ungrouped_face_test_df = face_df[face_df['s_Name'].isin(test_grouped_df['s_Name'].unique().tolist())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4f2a33-a150-4f4c-a454-99e5831cf78e",
   "metadata": {},
   "source": [
    "#### 8. Define the Autoencoder model\n",
    "The model will receive the audio embeddings and produce a predicted face embedding. <br>\n",
    "The loss is the mean averaged error between the predicted face embedding output and the avereraged face embedding of the same ID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b0ee73-4c23-42c7-a88d-bd75c014fc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_len = len(audio_cols)\n",
    "output_len = len(face_cols)\n",
    "\n",
    "model_AE_audio_face_1 = Sequential()\n",
    "model_AE_audio_face_1.add(Dense(input_len, input_shape=(input_len,)))\n",
    "model_AE_audio_face_1.add(LeakyReLU(alpha=0.1))\n",
    "model_AE_audio_face_1.add(BatchNormalization())\n",
    "model_AE_audio_face_1.add(Dense(input_len))\n",
    "model_AE_audio_face_1.add(LeakyReLU(alpha=0.1))\n",
    "model_AE_audio_face_1.add(BatchNormalization())\n",
    "model_AE_audio_face_1.add(Dense(input_len))\n",
    "model_AE_audio_face_1.add(LeakyReLU(alpha=0.1))\n",
    "model_AE_audio_face_1.add(BatchNormalization())\n",
    "model_AE_audio_face_1.add(Dense(input_len))\n",
    "model_AE_audio_face_1.add(LeakyReLU(alpha=0.1))\n",
    "model_AE_audio_face_1.add(BatchNormalization())\n",
    "model_AE_audio_face_1.add(Dense(input_len))\n",
    "model_AE_audio_face_1.add(LeakyReLU(alpha=0.1))\n",
    "model_AE_audio_face_1.add(BatchNormalization())\n",
    "model_AE_audio_face_1.add(Dense(input_len))\n",
    "model_AE_audio_face_1.add(LeakyReLU(alpha=0.1))\n",
    "model_AE_audio_face_1.add(BatchNormalization())\n",
    "model_AE_audio_face_1.add(Dense(input_len))\n",
    "model_AE_audio_face_1.add(LeakyReLU(alpha=0.1))\n",
    "model_AE_audio_face_1.add(Dense(128))\n",
    "model_AE_audio_face_1.add(LeakyReLU(alpha=0.1))\n",
    "model_AE_audio_face_1.add(Dense(64))\n",
    "model_AE_audio_face_1.add(LeakyReLU(alpha=0.1))\n",
    "model_AE_audio_face_1.add(Dense(256))\n",
    "model_AE_audio_face_1.add(LeakyReLU(alpha=0.1))\n",
    "model_AE_audio_face_1.add(Dense(output_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254310c5-dc35-485f-b933-65d530a000ea",
   "metadata": {},
   "source": [
    "#### 9. Train the model while saving iteration at the best validation loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "343ce378-2806-4ae2-b539-597d9dc8ed8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "721/726 [============================>.] - ETA: 0s - loss: 0.0382 - mae: 0.0382\n",
      "Epoch 00001: val_loss improved from inf to 0.03364, saving model to /home/drorco/DC_corsound_submission/checkpnt1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 19:51:32.739449: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/drorco/DC_corsound_submission/checkpnt1.pkl/assets\n",
      "726/726 [==============================] - 8s 8ms/step - loss: 0.0382 - mae: 0.0382 - val_loss: 0.0336 - val_mae: 0.0336\n",
      "Epoch 2/30\n",
      "725/726 [============================>.] - ETA: 0s - loss: 0.0337 - mae: 0.0337\n",
      "Epoch 00002: val_loss improved from 0.03364 to 0.03355, saving model to /home/drorco/DC_corsound_submission/checkpnt1.pkl\n",
      "INFO:tensorflow:Assets written to: /home/drorco/DC_corsound_submission/checkpnt1.pkl/assets\n",
      "726/726 [==============================] - 6s 8ms/step - loss: 0.0337 - mae: 0.0337 - val_loss: 0.0336 - val_mae: 0.0336\n",
      "Epoch 3/30\n",
      "717/726 [============================>.] - ETA: 0s - loss: 0.0337 - mae: 0.0337\n",
      "Epoch 00003: val_loss improved from 0.03355 to 0.03355, saving model to /home/drorco/DC_corsound_submission/checkpnt1.pkl\n",
      "INFO:tensorflow:Assets written to: /home/drorco/DC_corsound_submission/checkpnt1.pkl/assets\n",
      "726/726 [==============================] - 7s 9ms/step - loss: 0.0337 - mae: 0.0337 - val_loss: 0.0335 - val_mae: 0.0335\n",
      "Epoch 4/30\n",
      "720/726 [============================>.] - ETA: 0s - loss: 0.0337 - mae: 0.0337\n",
      "Epoch 00004: val_loss improved from 0.03355 to 0.03353, saving model to /home/drorco/DC_corsound_submission/checkpnt1.pkl\n",
      "INFO:tensorflow:Assets written to: /home/drorco/DC_corsound_submission/checkpnt1.pkl/assets\n",
      "726/726 [==============================] - 5s 7ms/step - loss: 0.0337 - mae: 0.0337 - val_loss: 0.0335 - val_mae: 0.0335\n",
      "Epoch 5/30\n",
      "720/726 [============================>.] - ETA: 0s - loss: 0.0336 - mae: 0.0336\n",
      "Epoch 00005: val_loss improved from 0.03353 to 0.03352, saving model to /home/drorco/DC_corsound_submission/checkpnt1.pkl\n",
      "INFO:tensorflow:Assets written to: /home/drorco/DC_corsound_submission/checkpnt1.pkl/assets\n",
      "726/726 [==============================] - 5s 7ms/step - loss: 0.0336 - mae: 0.0336 - val_loss: 0.0335 - val_mae: 0.0335\n",
      "Epoch 6/30\n",
      "719/726 [============================>.] - ETA: 0s - loss: 0.0336 - mae: 0.0336\n",
      "Epoch 00006: val_loss improved from 0.03352 to 0.03347, saving model to /home/drorco/DC_corsound_submission/checkpnt1.pkl\n",
      "INFO:tensorflow:Assets written to: /home/drorco/DC_corsound_submission/checkpnt1.pkl/assets\n",
      "726/726 [==============================] - 7s 9ms/step - loss: 0.0336 - mae: 0.0336 - val_loss: 0.0335 - val_mae: 0.0335\n",
      "Epoch 7/30\n",
      "723/726 [============================>.] - ETA: 0s - loss: 0.0334 - mae: 0.0334\n",
      "Epoch 00007: val_loss improved from 0.03347 to 0.03332, saving model to /home/drorco/DC_corsound_submission/checkpnt1.pkl\n",
      "INFO:tensorflow:Assets written to: /home/drorco/DC_corsound_submission/checkpnt1.pkl/assets\n",
      "726/726 [==============================] - 7s 9ms/step - loss: 0.0334 - mae: 0.0334 - val_loss: 0.0333 - val_mae: 0.0333\n",
      "Epoch 8/30\n",
      "725/726 [============================>.] - ETA: 0s - loss: 0.0331 - mae: 0.0331\n",
      "Epoch 00008: val_loss improved from 0.03332 to 0.03311, saving model to /home/drorco/DC_corsound_submission/checkpnt1.pkl\n",
      "INFO:tensorflow:Assets written to: /home/drorco/DC_corsound_submission/checkpnt1.pkl/assets\n",
      "726/726 [==============================] - 7s 10ms/step - loss: 0.0331 - mae: 0.0331 - val_loss: 0.0331 - val_mae: 0.0331\n",
      "Epoch 9/30\n",
      "717/726 [============================>.] - ETA: 0s - loss: 0.0328 - mae: 0.0328\n",
      "Epoch 00009: val_loss improved from 0.03311 to 0.03297, saving model to /home/drorco/DC_corsound_submission/checkpnt1.pkl\n",
      "INFO:tensorflow:Assets written to: /home/drorco/DC_corsound_submission/checkpnt1.pkl/assets\n",
      "726/726 [==============================] - 7s 10ms/step - loss: 0.0328 - mae: 0.0328 - val_loss: 0.0330 - val_mae: 0.0330\n",
      "Epoch 10/30\n",
      "725/726 [============================>.] - ETA: 0s - loss: 0.0325 - mae: 0.0325\n",
      "Epoch 00010: val_loss improved from 0.03297 to 0.03288, saving model to /home/drorco/DC_corsound_submission/checkpnt1.pkl\n",
      "INFO:tensorflow:Assets written to: /home/drorco/DC_corsound_submission/checkpnt1.pkl/assets\n",
      "726/726 [==============================] - 7s 9ms/step - loss: 0.0325 - mae: 0.0325 - val_loss: 0.0329 - val_mae: 0.0329\n",
      "Epoch 11/30\n",
      "721/726 [============================>.] - ETA: 0s - loss: 0.0323 - mae: 0.0323\n",
      "Epoch 00011: val_loss did not improve from 0.03288\n",
      "726/726 [==============================] - 4s 5ms/step - loss: 0.0323 - mae: 0.0323 - val_loss: 0.0329 - val_mae: 0.0329\n",
      "Epoch 12/30\n",
      "719/726 [============================>.] - ETA: 0s - loss: 0.0320 - mae: 0.0320\n",
      "Epoch 00012: val_loss did not improve from 0.03288\n",
      "726/726 [==============================] - 4s 5ms/step - loss: 0.0320 - mae: 0.0320 - val_loss: 0.0329 - val_mae: 0.0329\n",
      "Epoch 13/30\n",
      "720/726 [============================>.] - ETA: 0s - loss: 0.0318 - mae: 0.0318\n",
      "Epoch 00013: val_loss did not improve from 0.03288\n",
      "726/726 [==============================] - 3s 5ms/step - loss: 0.0318 - mae: 0.0318 - val_loss: 0.0329 - val_mae: 0.0329\n",
      "Epoch 14/30\n",
      "724/726 [============================>.] - ETA: 0s - loss: 0.0315 - mae: 0.0315\n",
      "Epoch 00014: val_loss did not improve from 0.03288\n",
      "726/726 [==============================] - 3s 5ms/step - loss: 0.0315 - mae: 0.0315 - val_loss: 0.0330 - val_mae: 0.0330\n",
      "Epoch 15/30\n",
      "714/726 [============================>.] - ETA: 0s - loss: 0.0313 - mae: 0.0313\n",
      "Epoch 00015: val_loss did not improve from 0.03288\n",
      "726/726 [==============================] - 4s 5ms/step - loss: 0.0313 - mae: 0.0313 - val_loss: 0.0330 - val_mae: 0.0330\n",
      "Epoch 16/30\n",
      "722/726 [============================>.] - ETA: 0s - loss: 0.0311 - mae: 0.0311\n",
      "Epoch 00016: val_loss did not improve from 0.03288\n",
      "726/726 [==============================] - 4s 5ms/step - loss: 0.0311 - mae: 0.0311 - val_loss: 0.0331 - val_mae: 0.0331\n",
      "Epoch 17/30\n",
      "720/726 [============================>.] - ETA: 0s - loss: 0.0309 - mae: 0.0309\n",
      "Epoch 00017: val_loss did not improve from 0.03288\n",
      "726/726 [==============================] - 4s 5ms/step - loss: 0.0309 - mae: 0.0309 - val_loss: 0.0331 - val_mae: 0.0331\n",
      "Epoch 18/30\n",
      "715/726 [============================>.] - ETA: 0s - loss: 0.0307 - mae: 0.0307\n",
      "Epoch 00018: val_loss did not improve from 0.03288\n",
      "726/726 [==============================] - 4s 5ms/step - loss: 0.0307 - mae: 0.0307 - val_loss: 0.0332 - val_mae: 0.0332\n",
      "Epoch 19/30\n",
      "715/726 [============================>.] - ETA: 0s - loss: 0.0306 - mae: 0.0306\n",
      "Epoch 00019: val_loss did not improve from 0.03288\n",
      "726/726 [==============================] - 3s 5ms/step - loss: 0.0306 - mae: 0.0306 - val_loss: 0.0332 - val_mae: 0.0332\n",
      "Epoch 20/30\n",
      "715/726 [============================>.] - ETA: 0s - loss: 0.0304 - mae: 0.0304\n",
      "Epoch 00020: val_loss did not improve from 0.03288\n",
      "726/726 [==============================] - 4s 5ms/step - loss: 0.0304 - mae: 0.0304 - val_loss: 0.0333 - val_mae: 0.0333\n",
      "Epoch 21/30\n",
      "714/726 [============================>.] - ETA: 0s - loss: 0.0302 - mae: 0.0302\n",
      "Epoch 00021: val_loss did not improve from 0.03288\n",
      "726/726 [==============================] - 3s 5ms/step - loss: 0.0302 - mae: 0.0302 - val_loss: 0.0334 - val_mae: 0.0334\n",
      "Epoch 22/30\n",
      "720/726 [============================>.] - ETA: 0s - loss: 0.0300 - mae: 0.0300\n",
      "Epoch 00022: val_loss did not improve from 0.03288\n",
      "726/726 [==============================] - 4s 6ms/step - loss: 0.0300 - mae: 0.0300 - val_loss: 0.0334 - val_mae: 0.0334\n",
      "Epoch 23/30\n",
      "725/726 [============================>.] - ETA: 0s - loss: 0.0299 - mae: 0.0299\n",
      "Epoch 00023: val_loss did not improve from 0.03288\n",
      "726/726 [==============================] - 4s 6ms/step - loss: 0.0299 - mae: 0.0299 - val_loss: 0.0335 - val_mae: 0.0335\n",
      "Epoch 24/30\n",
      "720/726 [============================>.] - ETA: 0s - loss: 0.0297 - mae: 0.0297\n",
      "Epoch 00024: val_loss did not improve from 0.03288\n",
      "726/726 [==============================] - 4s 5ms/step - loss: 0.0297 - mae: 0.0297 - val_loss: 0.0335 - val_mae: 0.0335\n",
      "Epoch 25/30\n",
      "717/726 [============================>.] - ETA: 0s - loss: 0.0295 - mae: 0.0295\n",
      "Epoch 00025: val_loss did not improve from 0.03288\n",
      "726/726 [==============================] - 4s 5ms/step - loss: 0.0295 - mae: 0.0295 - val_loss: 0.0336 - val_mae: 0.0336\n",
      "Epoch 26/30\n",
      "724/726 [============================>.] - ETA: 0s - loss: 0.0294 - mae: 0.0294\n",
      "Epoch 00026: val_loss did not improve from 0.03288\n",
      "726/726 [==============================] - 3s 5ms/step - loss: 0.0294 - mae: 0.0294 - val_loss: 0.0337 - val_mae: 0.0337\n",
      "Epoch 27/30\n",
      "715/726 [============================>.] - ETA: 0s - loss: 0.0292 - mae: 0.0292\n",
      "Epoch 00027: val_loss did not improve from 0.03288\n",
      "726/726 [==============================] - 4s 5ms/step - loss: 0.0292 - mae: 0.0292 - val_loss: 0.0338 - val_mae: 0.0338\n",
      "Epoch 28/30\n",
      "726/726 [==============================] - ETA: 0s - loss: 0.0291 - mae: 0.0291\n",
      "Epoch 00028: val_loss did not improve from 0.03288\n",
      "726/726 [==============================] - 3s 5ms/step - loss: 0.0291 - mae: 0.0291 - val_loss: 0.0338 - val_mae: 0.0338\n",
      "Epoch 29/30\n",
      "716/726 [============================>.] - ETA: 0s - loss: 0.0289 - mae: 0.0289\n",
      "Epoch 00029: val_loss did not improve from 0.03288\n",
      "726/726 [==============================] - 3s 5ms/step - loss: 0.0289 - mae: 0.0289 - val_loss: 0.0338 - val_mae: 0.0338\n",
      "Epoch 30/30\n",
      "724/726 [============================>.] - ETA: 0s - loss: 0.0288 - mae: 0.0288\n",
      "Epoch 00030: val_loss did not improve from 0.03288\n",
      "726/726 [==============================] - 4s 5ms/step - loss: 0.0288 - mae: 0.0288 - val_loss: 0.0339 - val_mae: 0.0339\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(learning_rate=0.0001)\n",
    "model_path = '/home/drorco/DC_corsound_submission/checkpnt1.pkl'\n",
    "chk_pnt = ModelCheckpoint(model_path, monitor='val_loss',save_best_only=True,mode='auto',verbose=1)\n",
    "model_AE_audio_face_1.compile(loss='mae',optimizer=adam, metrics=['mae'])\n",
    "history = model_AE_audio_face_1.fit(train_df[audio_cols],train_df[face_cols] ,epochs=30,callbacks=[chk_pnt],shuffle=True,batch_size=30,validation_data=(val_df[audio_cols],val_df[face_cols] ),verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfbfbc6-7ba2-4003-a6fc-bf554eb73be0",
   "metadata": {},
   "source": [
    "#### 10. Review the train and validation loss throughout the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abcb7535-d2cd-4aef-af42-0e60ecebae07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03, 0.035)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'],color='g',label='train_loss')\n",
    "plt.plot(history.history['val_loss'],color='b',label='val_loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim(0.03,0.035)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddfd36a-0612-4f65-b160-a9b5dbfaa98a",
   "metadata": {},
   "source": [
    "#### 11. load the best model based on the validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8e0cb5e-3bda-4426-b1cb-424188d3a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3a16a3-6cf0-44c3-99c2-9df5fc5dd0fd",
   "metadata": {},
   "source": [
    "#### 12. Create a predicted face embedding for each of the audio embedding in the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "062360ab-afdf-4be4-a6b6-1ca762707b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio = test_grouped_df[['s_Name','s_audio_fNum']+audio_cols]\n",
    "\n",
    "face_cols_preds = [col+'_pred' for col in face_cols]\n",
    "\n",
    "test_audio[face_cols_preds] = loaded_model.predict(test_audio[audio_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2974328e-e3f1-4c86-a1cf-11582742d2a2",
   "metadata": {},
   "source": [
    "#### 13. Evaluate the identification accuracy\n",
    "Here for each of the PREDICTED face embeddings (Anchor) is tested against a random positive and negative Actual face embedding samples. <br> A positive sample - one of the face embeddings of the same ID as the original audio embedding upon which the prediction was made. <br> A negative sample - one of the face embeddings of a different ID. <br> If it is closer to the positive sample it is considered as Correct identification . <br> If it is closer to the negative sample it is considered as False identification. <br> The accuracy is the percentage of correct identifications out of the entire test dataset. <br>\n",
    "For the sake of time, I choose not to generate all the possible combinations of audio-inputs, positive-face-embeddings, and negative-face embeddings as in the original identification accuracy metric. Instead, I generated predicted face embeddings from all audio-inputs, and compared them with randomly selected samples of positive and negative face embeddings as approximation of the identification accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3972710-1b85-4d3b-88ae-1db6d00a7950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is:  76.77000000000001 %\n"
     ]
    }
   ],
   "source": [
    "name_list = test_audio['s_Name'].unique().tolist()\n",
    "l=[]\n",
    "\n",
    "for name in name_list:\n",
    "    if name in (ungrouped_face_test_df['s_Name'].unique().tolist()):\n",
    "        \n",
    "        rndom_l = [rnd_name for rnd_name in name_list if rnd_name!=name]\n",
    "        rndom = random.choice(rndom_l)\n",
    "        \n",
    "        positive = ungrouped_face_test_df[(ungrouped_face_test_df['s_Name']==name)]\n",
    "        negative = ungrouped_face_test_df[(ungrouped_face_test_df['s_Name']==rndom)]\n",
    "\n",
    "        anchor = test_audio[test_audio['s_Name']==name].sort_values(by=['s_Name','s_audio_fNum'])\n",
    "        \n",
    "        if ((positive.shape[0]>0) and (anchor.shape[0]>0)):\n",
    "\n",
    "            for audio_fNum in anchor['s_audio_fNum'].unique().tolist():\n",
    "                \n",
    "                curr_pair = positive.sample().append(negative.sample())\n",
    "                            \n",
    "                knn = KNeighborsClassifier(n_neighbors=1)\n",
    "                knn.fit(curr_pair[face_cols], curr_pair['s_Name'])               \n",
    "                \n",
    "                pred_name = knn.predict(anchor[anchor['s_audio_fNum']==audio_fNum][face_cols_preds])\n",
    "                \n",
    "                l.append(int(pred_name==anchor[anchor['s_audio_fNum']==audio_fNum]['s_Name']))\n",
    "                \n",
    "print('The Accuracy is: ', round(sum(l)/len(l),4)*100, '%')              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98418cc1-519d-4450-a162-86f0ec00488b",
   "metadata": {},
   "source": [
    "#### Overall, the achieved accuracy was in the expected boundaries (75%-80%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b74953a-00f2-47a6-ae2a-c8bd81c0a6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
